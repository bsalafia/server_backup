# -*- coding: utf-8 -*-
"""FineTunningEvaluateGRUMedium.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jYT_wp5KfMLguTijhYdFAqfhtNrHixMZ
"""

import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="1"
import tensorflow as tf
import statistics
import scipy
import h5py
import glob, os
from scipy.io import loadmat
from sklearn.model_selection import KFold
from keras.models import Model
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
# from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten,TimeDistributed, GRU,Concatenate
from keras.optimizers import Adam
from keras.layers.normalization import BatchNormalization
from keras.utils import np_utils
from keras.layers import Conv1D, GlobalAveragePooling1D,MaxPooling1D
from keras.layers.advanced_activations import LeakyReLU
from keras.preprocessing.image import ImageDataGenerator
from sklearn import preprocessing
from keras import regularizers
from numpy import mean
from numpy import std
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from tensorflow.keras.datasets import cifar10
from keras.optimizers import Adam
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.metrics import f1_score,plot_roc_curve
from sklearn.metrics import plot_precision_recall_curve,roc_curve,roc_auc_score,auc
from sklearn.metrics import precision_recall_fscore_support,precision_recall_curve
from keras.layers.normalization import BatchNormalization
from keras.utils import np_utils
from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D, GlobalAveragePooling1D,Bidirectional
from keras.layers.advanced_activations import LeakyReLU
from keras.preprocessing.image import ImageDataGenerator
from sklearn import preprocessing
from keras import regularizers
from numpy import mean
from numpy import std
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.layers import InputLayer
from keras.layers import Input
import time
import gc
# from google.colab import drive

# drive.mount('/content/drive')

def PatientsName():

  Name=['chb01','chb02','chb03','chb04','chb05','chb06','chb07','chb08','chb09','chb10',
  'chb11','chb12','chb13','chb14','chb15','chb16','chb17','chb18','chb19','chb20','chb21',
  'chb22','chb23','chb24']
  return Name

def PatientsEDFFile(dirname):

  os.chdir(dirname)
  a=[]
  X=[]
  Y=[]
  k=0
  for file in glob.glob("*.mat"):
      a.append(file)
      # print(a)
  return a

def  Conv_BN_Act_Pool(filtNo,filtsize1,filtsize2,input1,activation,PoolSize):
    conv1 = Conv1D(filtNo,filtsize1)(input1)
    conv2 = Conv1D(filtNo, filtsize2)(conv1)
    BN=BatchNormalization(axis=-1)(conv2)
    ActFunc=Activation(activation)(BN)
    pool1=MaxPooling1D(pool_size=PoolSize)(ActFunc)

    return pool1

def create_sub_seq(nn_input, len_ss, labels=None):

  n_seq = nn_input.shape[0]
  len_seq = nn_input.shape[1]
  n_ss = len_seq - len_ss + 1
  new_labels = []
  if nn_input.ndim == 3:
    new_inp = np.zeros((n_ss*n_seq,len_ss,nn_input.shape[2]))
  elif nn_input.ndim == 4:
    new_inp = np.zeros((n_ss*n_seq,len_ss,nn_input.shape[2], nn_input.shape[3]))
  if labels is not None:
      dim_labels = labels.shape
      if len(dim_labels) == 2:
          new_labels = np.zeros((n_ss*n_seq, len_ss))
      elif len(dim_labels) == 3:
          new_labels = np.zeros((n_ss * n_seq, len_ss, dim_labels[2]))
  k = 0
  for i in range(n_seq):
      for j in range(n_ss):
          new_inp[k] = nn_input[i, j:j + len_ss, :]
          if labels is not None:
              if len(dim_labels) == 2:
                  new_labels[k, :] = labels[i, j:j + len_ss]
              elif len(dim_labels) == 3:
                  new_labels[k, :, :] = labels[i, j:j + len_ss, :]
          k += 1
  return new_inp, n_ss, new_labels

def sample_weight_func(y):

    from sklearn.utils import class_weight
    cw = class_weight.compute_class_weight('balanced', np.unique(y),np.ravel(y))
    print(cw)
    class_weights = {0:cw[0], 1: cw[1]}

    return class_weights

def dataloader(x,mi,y,seq_len, cnn,smile,diff,twodcnn):


  MI_all=[]
  X=[]
  Y=[]
  MI_diff_all=[]
  # print('flag')
  # y=np.transpose(y)
  start_idx = np.argmax(y>0)
  a = y == 1
  end_idx = len(a) - np.argmax(np.flip(a)) - 1
  real_y = np.zeros_like(y)
  real_y[start_idx:end_idx+1] = 1
  MI=np.zeros((mi.shape[0],153))
  for j in range(mi.shape[0]):
    mi2=mi[j,:,:]
    mi_mod=list(mi2[np.triu_indices(18,k=1)])
    MI[j,:]=mi_mod
  MI_diff=[]
  if seq_len > 1:
    real_y = np.expand_dims(real_y, axis=0)
    x = np.expand_dims(x, axis=0)
    MI = np.expand_dims(MI, axis=0)
    # print('flag')
    x, _ , real_y = create_sub_seq(x, seq_len, labels=real_y)
    MI, _, _ = create_sub_seq(MI, seq_len)

  if diff is not None:
    for j in range(MI.shape[0]-1):
      MI_diff.append(MI[j+1]-MI[j])
    MI_diff=np.array(MI_diff)
    MI=MI[1:]
    x=x[1:]
    real_y=real_y[1:]



  return x,real_y,MI,MI_diff

def FineTuning(SaveResults,modelname,fold_no,x1,y1,mi1,mi_diff1,batchsize,epoch,Xtest,MItest,MItest_diff,cnn,smile,diff,twodcnn,Noepoch,l2_size,drop_size,batchSize):

  if cnn==1:
    X_train=x1
    X_test=Xtest

  if smile==1:
    X_train=[x1,mi1]
    X_test=[Xtest,MItest]

  if diff==1:

    X_train=[x1,mi1,mi_diff1]

    X_test=[Xtest,MItest,MItest_diff]

  if twodcnn==1:

    x1=x1.reshape(x1.shape[0],x1.shape[2],x1.shape[1],1)
    Xtest=Xtest.reshape(Xtest.shape[0],Xtest.shape[2],Xtest.shape[1],1)
    X_train=x1
    X_test=Xtest

  ModelName=modelname+'_fold'+str(fold_no)+'_epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)+'.h5'

  model=tf.keras.models.load_model(os.path.join(SaveResults,ModelName))
  sample_weights=sample_weight_func(y1)
  model.fit(X_train,y1, validation_split=0, batch_size=batchsize, epochs=epoch, class_weight=sample_weights, verbose = 2)
  ypred=model.predict(X_test)

  return ypred,model

def ReadMatFiles(dirname,SaveResults,indx,fold_no,modelname,batchsize,epoch ,cnn,smile,diff,twodcnn,seq_len,Noepoch,l2_size,drop_size,batchSize):


  EDF=[]
  EDFFiles=[]
  Name=[]
  EDF=PatientsEDFFile(dirname)
  Name=PatientsName()
  Xfile=[]
  Yfile=[]
  ind=[]

  Ytest_all=[]
  Ypred_all=[]

  Xtest=[]
  Ytest=[]
  MItest=[]
  MItest_diff=[]

  for j in list(indx):
    # print(j)
    indices = [i for i, elem in enumerate(EDF) if Name[j] in elem]
    ind.append(indices)
  # print(ind[1][:])
  # ind=np.concatenate(ind,axis=0)
  cnt=0

  for k in range(len(ind)):
    Xtest=[]
    Ytest=[]
    MItest=[]
    MItest_diff=[]
    shapes=[]
    for z in ind[k]:

      mat=loadmat(os.path.join(dirname,EDF[int(z)]))

      x=mat['X_4sec']
      shape1=x.shape[0]
      shapes.append(shape1)

    MediumShape=min(shapes, key=lambda x:abs(x-statistics.median(shapes)))
    index = shapes.index(MediumShape)

    matfiletrain=loadmat(os.path.join(dirname,EDF[int(ind[k][index])]))

    # print(EDF[int(ind[k][index])])
    xtrain=matfiletrain['X_4sec']
    ytrain=matfiletrain['Y_label_4sec']
    mitrain=matfiletrain['estimated_MI']
    x1,y1,mi1,mi_diff1=dataloader(xtrain,mitrain,ytrain,seq_len,cnn,smile,diff,twodcnn)
    # print(x1.shape)

    for q in [p for p in ind[k] if p != index]:

      matfile=loadmat(os.path.join(dirname,EDF[q]))
      # print(EDF[q])
      xt=matfile['X_4sec']
      yt=matfile['Y_label_4sec']
      mit=matfile['estimated_MI']
      Xt,Yt,MIt,MI_difft=dataloader(xt,mit,yt,seq_len,cnn,smile,diff,twodcnn)
      print(Yt.shape)
      Xtest.append(Xt)
      MItest.append(MIt)
      MItest_diff.append(MI_difft)
      Ytest.append(Yt)

    Xtest2=np.concatenate(Xtest,axis=0)
    Ytest2=np.concatenate(Ytest,axis=0)
    MItest2=np.concatenate(MItest,axis=0)
    MItest_diff2=np.concatenate(MItest_diff,axis=0)

    ypred,model=FineTuning(SaveResults,modelname,fold_no,x1,y1,mi1,mi_diff1,batchsize,epoch,Xtest2,MItest2,MItest_diff2,cnn,smile,diff,twodcnn,Noepoch,l2_size,drop_size,batchSize)

    Ypred_all.append(ypred)
    Ytest_all.append(Ytest2)


  return Xtest,Ytest,MItest,MItest_diff,Ytest_all,Ypred_all,model

def Xtrain(cnn,smile,diff,twodcnn,x,y,mi,mi_diff):

  if cnn==1:
    X_train=x
  if smile==1:
    X_train=[x,mi]
  if diff==1:
    X_train=[x,mi,mi_diff]

  if twodcnn==1:
    x2d=x.reshape(x.shape[0],x.shape[2],x.shape[1],1)
    X_train=x2d

  return X_train


def ModelTrain(dirname,modeldir,SaveResults,SaveResultsTruePred,modelname,seq_len,cnn,smile,diff,twodcnn,indx,gru,Noepoch,l2_size,drop_size,batchSize):

  fpr=[]
  tpr=[]
  PR=[]
  ROC=[]
  pred=[]
  act=[]
  fscore=[]
  batchsize=256
  epoch=3


  FoldNum=6
  kfold = KFold(n_splits=FoldNum, shuffle=False)
  start_time = time.time()

  savenamef1='fscore_'+modelname+'_'+indx+'_'+'epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)
  cfname='cfmat_'+modelname+'_'+indx+'_'+'epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)
  fprname='fpr_'+modelname+'_'+indx+'_'+'epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)
  tprname='tpr_'+modelname+'_'+indx+'_'+'epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)
  prname='PR_'+modelname+'_'+indx+'_'+'epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)
  rocname='ROC_'+modelname+'_'+indx+'_'+'epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)

  kfold = KFold(n_splits=FoldNum, shuffle=False)


  test=[]
  for th in [0.5]:

    fpr=[]
    tpr=[]
    PR=[]
    ROC=[]
    pred=[]
    act=[]
    fscore=[]

    fold_no=0
    for trainindx, testindx in kfold.split(range(24)):

      fold_no=fold_no+1

      if indx=='test_finetune':

        ind=testindx
      else:

        ind=trainindx

      _,_,_,_,Ytest_all,Ypred_all,model=ReadMatFiles(dirname,modeldir,ind,fold_no,modelname,batchsize,epoch ,cnn,smile,diff,twodcnn,seq_len,Noepoch,l2_size,drop_size,batchSize)

      model.save(modeldir+'/'+modelname+'_fold'+str(fold_no)+'_epoch_'+str(Noepoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)+'_'+indx+'.h5')

      for i in range(len(Ytest_all)):


        if gru==1:

          yp= Ypred_all[i][:, 2]
          yt= Ytest_all[i][:, 2]
          yp_th=(yp > th).astype(int)

        else:

          yp= Ypred_all[i]
          yt= Ytest_all[i]
          yp_th=(yp > th).astype(int)

        if th==0.5:

          fpr1, tpr1, _ = roc_curve(yt, yp)
          precision, recall, _ = precision_recall_curve(yt, yp)
          PR1=auc(recall, precision)
          ROC1=roc_auc_score(yt,yp)
          fpr.append(fpr1)
          tpr.append(tpr1)
          PR.append(PR1)
          ROC.append(ROC1)

        precision, recall, f1, _ = precision_recall_fscore_support(yt, yp_th, average='weighted')
        fscore.append(f1)
        pred.append(list(yp_th))
        act.append(list(yt))

    pred1=np.concatenate(pred,axis=0)
    act1=np.concatenate(act,axis=0)
    cnf_matrix = confusion_matrix(act1, pred1)
    np.save(os.path.join(SaveResults, savenamef1+str(th)),  fscore)
    np.save(os.path.join(SaveResults, cfname+str(th)),  cnf_matrix)


    np.save(os.path.join(SaveResults, fprname),  fpr)
    np.save(os.path.join(SaveResults, tprname),  tpr)
    np.save(os.path.join(SaveResults, prname), PR)
    np.save(os.path.join(SaveResults, rocname),  ROC)


   ####################################
  tf.keras.backend.clear_session()
  for k in range(3):

    fold_no=0
    FoldNum=6
    kfold = KFold(n_splits=FoldNum, shuffle=False)
    for trainindx, testindx in kfold.split(range(24)):
      if indx=='test_finetune':

        ind=testindx
      else:

        ind=trainindx

      fold_no=fold_no+1
      x,y,mi,mi_diff,_,_,model=ReadMatFiles(dirname,modeldir,ind,fold_no,modelname,batchsize,epoch ,cnn,smile,diff,twodcnn,seq_len,Noepoch,l2_size,drop_size,batchSize)




      X_train=Xtrain(cnn,smile,diff,twodcnn,x[k],y[k],mi[k],mi_diff[k])
      ypred_plot=model.predict(X_train)
      print(len(y[k]))
      if gru==1:
        y = y[k][:, 2]
        ypred_plot= ypred_plot[:, 2]
        # y=y.reshape(len(y),1)
      else:
        y = y[k]
        # y=y.reshape(len(y),1)
      ypred_plot=np.squeeze(ypred_plot)
      # y=np.squeeze(y)
      # print(ypred_plot.shape)
      plt.subplot(3,2,fold_no)
      plt.plot(range(y.shape[0]), y)
      plt.plot(range(y.shape[0]),ypred_plot)

    plt.suptitle(modelname+'_EDFNo_'+str(k+1)+'_epoch_'+str(Noepoch)+'_'+indx+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize))
    plt.savefig(SaveResultsTruePred+'/'+modelname+'_EDFNo_'+str(k+1)+'_epoch_'+str(Noepoch)+'_'+indx+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)+'.pdf', format='pdf', bbox_inches = 'tight')
    plt.clf()


  print("--- %s seconds ---" % (time.time() - start_time))

dirname='/home/baharsalafian/6FoldData3times'
modeldir='/home/baharsalafian/CNNSMILEGRU100Epoch_L2DropExperiment'

      # SaveHisResults='/home/baharsalafian/HistoryResExperiment'
SaveResults='/home/baharsalafian/Results_L2DropExperiment_Final'
SaveResultsTruePred='/home/baharsalafian/TruePredPlots_Experiment_Final'
i=0.1
k=0.01
j=256

ModelTrain(dirname,modeldir,SaveResults,SaveResultsTruePred,'CNN3times',seq_len=1,cnn=1,smile=0,diff=0,twodcnn=0,indx='test_finetune',gru=0,Noepoch=350,l2_size=k,drop_size=i,batchSize=j)
