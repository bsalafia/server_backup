# -*- coding: utf-8 -*-
"""Copy of CNNSMILEGRU_Bs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fgyv5Og_PPfexz3ih-4uEJqa-PfQsKSA
"""

import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="4"
from keras.models import Model
from keras.utils.generic_utils import get_custom_objects
from keras import optimizers, regularizers
import keras.backend as K
from keras import regularizers
from tensorflow.keras.layers import InputLayer
from keras.layers import Input
import time
import tensorflow as tf
import os
import scipy
import h5py
import glob, os
# import BaseLineModel
from scipy.io import loadmat
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
# from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten,Concatenate
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.metrics import f1_score,plot_roc_curve,accuracy_score
from sklearn.metrics import plot_precision_recall_curve,roc_curve,roc_auc_score,auc
from sklearn.metrics import precision_recall_fscore_support,precision_recall_curve
import matplotlib.pyplot as plt;
from keras.optimizers import Adam
from keras.layers.normalization import BatchNormalization
from keras.utils import np_utils
from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D, GlobalAveragePooling1D
from keras.layers.advanced_activations import LeakyReLU
from keras.preprocessing.image import ImageDataGenerator
from sklearn import preprocessing
from keras import regularizers
from numpy import mean
from numpy import std
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.layers import InputLayer
from keras.layers import Input
# from google.colab import drive
from sklearn.model_selection import LeaveOneOut
import gc
gc.collect()

def PatientsName():

  Name=['chb01','chb02','chb03','chb04','chb05','chb06','chb07','chb08','chb09','chb10',
  'chb11','chb12','chb13','chb14','chb15','chb16','chb17','chb18','chb19','chb20','chb21',
  'chb22','chb23','chb24']
  return Name

def PatientsEDFFile(dirname):

  os.chdir(dirname)
  a=[]
  X=[]
  Y=[]
  k=0
  for file in glob.glob("*.mat"):
      a.append(file)
      # print(a)
  return a

def recall2(y_true, y_pred):

  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
  recall_m = true_positives / (possible_positives + K.epsilon())
  return recall_m

def precision(y_true, y_pred):

  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
  precision_m = true_positives / (predicted_positives + K.epsilon())
  return precision_m

def AUCPR(y_true, y_pred):

  precision, recall, _ = precision_recall_curve(y_true, y_pred)

  PR1=auc(recall, precision)

  return PR1
# def f1_score(y_true, y_pred):
  # precision_m = precision(y_true, y_pred)
  # recall_m = recall(y_true, y_pred)
  # return 2*((precision_m*recall_m)/(precision_m+recall_m+K.epsilon()))
def f1_score(y_true, y_pred,threshold_shift=0):

  y_pred = K.clip(y_pred, 0, 1)
  # shifting the prediction threshold from .5 if needed
  y_pred_bin = K.round(y_pred + threshold_shift)
  tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()
  fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))
  fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))
  precision1 = tp / (tp + fp)
  recall1 = tp / (tp + fn)
  p = precision1
  r = recall1
  return 2 * ((p * r) / (p + r))

def auc_roc(y_true, y_pred):

  return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)

def auc_pr(y_true, y_pred):

  return tf.py_function(AUCPR, (y_true, y_pred), tf.double)


def  Conv_BN_Act_Pool(filtNo,filtsize1,filtsize2,input1,activation,PoolSize):
    conv1 = Conv1D(filtNo,filtsize1)(input1)
    conv2 = Conv1D(filtNo, filtsize2)(conv1)
    BN=BatchNormalization(axis=-1)(conv2)
    ActFunc=Activation(activation)(BN)
    pool1=MaxPooling1D(pool_size=PoolSize)(ActFunc)

    return pool1

def define_SMILE():

  vectorsize=18
  input_shape=(1024,18)
  denseSize=8
  activation='relu'
  filtsize1=22
  filtNo1=8
  filtsize2=10
  filtNo2=16
  PoolSize=2
  input1 = Input(input_shape)
  model1=Conv_BN_Act_Pool(filtNo1,filtsize2,filtsize1,input1,activation,PoolSize)
  model2=Conv_BN_Act_Pool(filtNo1,filtsize2,filtsize1,model1,activation,PoolSize)
  model3=Conv_BN_Act_Pool(filtNo1,filtsize2,filtsize1,model2,activation,PoolSize)
  model4=Conv_BN_Act_Pool(filtNo2,filtsize2,filtsize1,model3,activation,PoolSize)
  model5=Conv_BN_Act_Pool(filtNo2,filtsize2,filtsize1,model4,activation,PoolSize)
  conv6=Conv1D(filtNo1,1)(model5)
  drop1=Dropout(0.25)(conv6)

  flat=Flatten()(drop1)
  dense=Dense(denseSize)(flat)
################################################################
  dim_data =int(vectorsize*(vectorsize+1)/2)-18
  vector_input = Input((dim_data,))
  # Concatenate the convolutional features and the vector input
  concat_layer= Concatenate()([flat,vector_input])
  denseout = Dense(100, activation='relu')(concat_layer)
  denseout = Dense(50, activation='relu')(denseout)
  output = Dense(1, activation='sigmoid')(denseout)

  # define a model with a list of two inputs
  model = Model(inputs=[input1, vector_input], outputs=output)
  model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy', metrics=['accuracy'])
  return model

def define_CNN():


    model = Sequential()

    filter1=8
    filter2=16

    kernelsize1=22
    kernelsize2=10

    model.add(Conv1D(filter1, kernelsize2, input_shape=(1024,18)))
    model.add(Conv1D(filter1, kernelsize1))
    model.add(BatchNormalization(axis=-1))
    model.add(Activation('relu'))
    model.add(MaxPooling1D(pool_size=2))

    model.add(Conv1D(filter1, kernelsize2))
    model.add(Conv1D(filter1, kernelsize1))
    model.add(BatchNormalization(axis=-1))
    model.add(Activation('relu'))
    model.add(MaxPooling1D(pool_size=2))

    model.add(Conv1D(filter1, kernelsize2))
    model.add(Conv1D(filter1, kernelsize1))
    model.add(BatchNormalization(axis=-1))
    model.add(Activation('relu'))
    model.add(MaxPooling1D(pool_size=2))

    model.add(Conv1D(filter2, kernelsize2))
    model.add(Conv1D(filter2, kernelsize1))
    model.add(BatchNormalization(axis=-1))
    model.add(Activation('relu'))
    model.add(MaxPooling1D(pool_size=2))

    model.add(Conv1D(filter2, kernelsize2))
    model.add(Conv1D(filter2, kernelsize1))
    model.add(BatchNormalization(axis=-1))
    model.add(Activation('relu'))
    model.add(MaxPooling1D(pool_size=2))

    model.add(Conv1D(filter1, 1))

    model.add(Dropout(0.25))
    model.add(Flatten())

# Fully connected layer

    model.add(Dense(8))
    model.add(Dense(8))
    model.add(Dropout(0.5))

    model.add(Dense(1))
    model.add(Activation('sigmoid'))
    model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy', metrics=['accuracy'])

    return model

def define_CNNSMILEDiff():
    vectorsize=18
    input_shape=(1024,18)
    denseSize=8
    activation='relu'

    filtsize1=22
    filtNo1=8
    filtsize2=10
    filtNo2=16

    PoolSize=2

    input1 = Input(input_shape)

    model1=Conv_BN_Act_Pool(filtNo1,filtsize2,filtsize1,input1,activation,PoolSize)
    model2=Conv_BN_Act_Pool(filtNo1,filtsize2,filtsize1,model1,activation,PoolSize)
    model3=Conv_BN_Act_Pool(filtNo1,filtsize2,filtsize1,model2,activation,PoolSize)
    model4=Conv_BN_Act_Pool(filtNo2,filtsize2,filtsize1,model3,activation,PoolSize)
    model5=Conv_BN_Act_Pool(filtNo2,filtsize2,filtsize1,model4,activation,PoolSize)


    conv6=Conv1D(filtNo1,1)(model5)
    drop1=Dropout(0.25)(conv6)
    flat=Flatten()(drop1)

# Fully connected layer

    dense=Dense(denseSize)(flat)
##################################################################
    dim_data =int(vectorsize*(vectorsize+1)/2)-18
    vector_input1 = Input((dim_data,))
    vector_input2 = Input((dim_data,))
    # Concatenate the convolutional features and the vector input
    concat_layer= Concatenate()([flat,vector_input1,vector_input2])
    denseout = Dense(100, activation='relu')(concat_layer)
    denseout = Dense(50, activation='relu')(denseout)
    output = Dense(1, activation='sigmoid')(denseout)

    # define a model with a list of two inputs
    model = Model(inputs=[input1, vector_input1,vector_input2], outputs=output)


    model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy', metrics=['accuracy'])

    return model

def create_sub_seq(nn_input, len_ss, labels=None):

  """
  This function creates all sub sequences for the batch
  """
  n_seq = nn_input.shape[0]
  len_seq = nn_input.shape[1]
  n_ss = len_seq - len_ss + 1
  new_labels = []
  if nn_input.ndim == 3:
    new_inp = np.zeros((n_ss*n_seq,len_ss,nn_input.shape[2]))
  elif nn_input.ndim == 4:
    new_inp = np.zeros((n_ss*n_seq,len_ss,nn_input.shape[2], nn_input.shape[3]))
  if labels is not None:
      dim_labels = labels.shape
      if len(dim_labels) == 2:
          new_labels = np.zeros((n_ss*n_seq, len_ss))
      elif len(dim_labels) == 3:
          new_labels = np.zeros((n_ss * n_seq, len_ss, dim_labels[2]))
  k = 0
  for i in range(n_seq):
      for j in range(n_ss):
          new_inp[k] = nn_input[i, j:j + len_ss, :]
          if labels is not None:
              if len(dim_labels) == 2:
                  new_labels[k, :] = labels[i, j:j + len_ss]
              elif len(dim_labels) == 3:
                  new_labels[k, :, :] = labels[i, j:j + len_ss, :]
          k += 1
  return new_inp, n_ss, new_labels

def ReadMatFiles(dirname,dirname2,indx, seq_len=1,diff=None):

  EDF=[]
  EDFFiles=[]
  Name=[]
  EDF=PatientsEDFFile(dirname)
  Name=PatientsName()
  Xfile=[]
  Yfile=[]
  ind=[]

  MI_all=[]
  X=[]
  Y=[]
  MI_diff_all=[]
  Spect_all=[]

  X_final=[]
  Y_final=[]
  MI_diff_final=[]
  MI_final=[]
  Spect_final=[]

  X_plot=[]
  Y_plot=[]
  MI_all_plot=[]
  MI_diff_all_plot=[]
  Spect_plot=[]

  for j in list(indx):
    print(j)
    indices = [i for i, elem in enumerate(EDF) if Name[j] in elem]
    ind.append(indices)

    print(indices)

    # time.sleep(2)

  # ind=np.concatenate(ind,axis=0)
  print(len(ind[0]))
  for k in range(len(ind)):
    for q in range(len(ind[k])):

    # print(ind[k])
      matfile=loadmat(os.path.join(dirname,EDF[int(ind[k][q])]))
      Name2=EDF[int(ind[k][q])].split('.')

      matfile2=loadmat(os.path.join(dirname2,EDF[int(ind[k][q])]))
      spect=matfile2['spectogram']

      print(EDF[int(ind[k][q])])
      x=matfile['X_4sec']
      y=matfile['Y_label_4sec']
      mi=matfile['estimated_MI']
      y=np.transpose(y)
      start_idx = np.argmax(y>0)
      a = y == 1
      end_idx = len(a) - np.argmax(np.flip(a)) - 1
      real_y = np.zeros_like(y)
      real_y[start_idx:end_idx+1] = 1
      # MI=mi
      MI=np.zeros((mi.shape[0],153))
      for j in range(mi.shape[0]):
        mi2=mi[j,:,:]
        mi_mod=list(mi2[np.triu_indices(18,k=1)])
        MI[j,:]=mi_mod


      MI_diff=[]
      if seq_len > 1:
        real_y = np.expand_dims(real_y, axis=0)
        x = np.expand_dims(x, axis=0)
        MI = np.expand_dims(MI, axis=0)
      # print(MI.shape)
        x, _ , real_y = create_sub_seq(x, seq_len, labels=real_y)
        MI, _, _ = create_sub_seq(MI, seq_len)
        spect, _, _ = create_sub_seq(spect, seq_len)
      # print(x.shape)
      # print(real_y.shape)
      # print(MI.shape)

      if diff is not None:

        for j in range(MI.shape[0]-1):

          MI_diff.append(MI[j+1]-MI[j])

        MI_diff=np.array(MI_diff)
        MI=MI[1:]
        x=x[1:]
        real_y=real_y[1:]
        spect=spect[1:]
      X.append(x)
      Y.append(real_y)
      MI_all.append(MI)
      MI_diff_all.append(MI_diff)

      Spect_all.append(spect)

      X_plot.append(x)
      Y_plot.append(real_y)
      MI_all_plot.append(MI)
      MI_diff_all_plot.append(MI_diff)
      Spect_plot.append(spect)

    X=np.concatenate(X,axis=0)
    Y=np.concatenate(Y,axis=0)
    MI_all=np.concatenate(MI_all,axis=0)
    MI_diff_all=np.concatenate(MI_diff_all,axis=0)
    Spect_all=np.concatenate(Spect_all,axis=0)

    X_final.append(X)
    Y_final.append(Y)
    MI_diff_final.append(MI_all)
    MI_final.append(MI_diff_all)
    Spect_final.append(Spect_all)

    MI_all=[]
    X=[]
    Y=[]
    MI_diff_all=[]
    Spect_all=[]


  #
  # print(X.shape)
  # print(Y.shape)
  # print(MI_all.shape)
  # print(MI_diff_all.shape)

  return X_final, Y_final, MI_final, MI_diff_final,Spect_final,X_plot,Y_plot,MI_all_plot,MI_diff_all_plot,Spect_plot

def Xtrain(cnn,spect,smile,diff,smile_new_arch,twodcnn,cnnsmilespect,x,y,mi,mi_diff,Spect_all):

  if cnn==1:
    X_train=x

  if spect==1:
    X_train=Spect_all

  if smile==1:
    X_train=[x,mi]
    # X_train=np.concatenate((x,mi),axis=1)

  if diff==1:
    X_train=[x,mi,mi_diff]

  if twodcnn==1:
    x2d=x.reshape(x.shape[0],x.shape[2],x.shape[1],1)
    X_train=x2d

  if cnnsmilespect==1:
    X_train=[x,Spect_all,mi]

  if smile_new_arch==1:
    X_train=[x,mi]


  return X_train







def ModelTrain(dirname,dirname2,modeldir,SaveResults,SaveResultsTruePred,modelname,seq_len,cnn,spect1,smile,diff,twodcnn,cnnsmilespect,smile_new_arch,indx,gru,Noepoch,batch_size):

  FoldNum=6
  kfold = KFold(n_splits=FoldNum, shuffle=False)
  start_time = time.time()
  fold_no=0

  savenamef1='fscore_'+modelname+'_'+indx+'_'+str(Noepoch)+'_'
  cfname='cfmat_'+modelname+'_'+indx+'_'+str(Noepoch)+'_'
  fprname='fpr_'+modelname+'_'+indx+'_'+str(Noepoch)
  tprname='tpr_'+modelname+'_'+indx+'_'+str(Noepoch)
  prname='PR_'+modelname+'_'+indx+'_'+str(Noepoch)
  rocname='ROC_'+modelname+'_'+indx+'_'+str(Noepoch)
  precname='Precision_'+modelname+'_'+indx+'_'+str(Noepoch)

  recname='Recall_'+modelname+'_'+indx+'_'+str(Noepoch)
  accname='Accuracy_'+modelname+'_'+indx+'_'+str(Noepoch)



  for th in [0.5]:

    fold_no=0

    AUC_PR=[]
    AUC_ROC=[]
    Precision=[]
    Recall=[]
    f1score=[]
    cnf_matrix=[]
    accuracy=[]


    for trainindx, testindx in kfold.split(range(24)):


      if indx=='test':
        ind=testindx
      else:
        ind=trainindx

      x, y, mi,mi_diff,spect,_,_,_,_,_=ReadMatFiles(dirname,dirname2,ind,seq_len,diff)

      print('for test length', len(x))

      fold_no=fold_no+1


      ModelName1=modelname+'_fold'+str(fold_no)+'_epoch_'+str(Noepoch)+'_batchsize_'+str(batch_size)+'LR0.0001'+'.h5'
      # model = keras.models.load_model('model.h5', custom_objects={'HammingScore': HammingScore} )
      model1=tf.keras.models.load_model(os.path.join(modeldir,ModelName1),custom_objects={"f1_score":f1_score,"auc_roc":auc_roc,"precision":precision,"recall2":recall2,"auc_pr":auc_pr})
      # X=np.concatenate(x,axis=0)
      fpr=[]
      tpr=[]
      PR=[]
      ROC=[]
      pred=[]
      act=[]
      fscore=[]
      prec=[]
      rec=[]
      Acc=[]
      # print(X.shape[0])
      for k in range(len(x)):


        X=x[k]
        Y=y[k]
        MI_all=mi[k]
        MI_diff_all=mi_diff[k]

        Spect_all=spect[k]


        X_train=Xtrain(cnn,spect1,smile,diff,smile_new_arch,twodcnn,cnnsmilespect,X,Y,MI_all,MI_diff_all,Spect_all)

        ypred=model1.predict(X_train)
        ypred_th = (ypred > th).astype(int)

        if gru==1:

          Y = Y[:, 2]
          ypred= ypred[:, 2]
          ypred_th= ypred_th[:, 2]

        # if th==0.5:
        fpr1, tpr1, _ = roc_curve(Y, ypred)
        PR1=AUCPR(Y, ypred)
        ROC1=roc_auc_score(Y,ypred)
        fpr.append(fpr1)
        tpr.append(tpr1)

        PR.append(PR1)
        ROC.append(ROC1)

        Acc.append(accuracy_score(Y,ypred_th))
  #
        Precision1, Recall1, f1, _ = precision_recall_fscore_support(Y, ypred_th, average='binary')
  #
        pred.append(list(ypred_th))
        act.append(list(Y))
        fscore.append(f1)
        prec.append(Precision1)
        rec.append(Recall1)

      accuracy.append(np.mean(np.array(Acc),axis=0))

      AUC_PR.append(np.mean(np.array(PR),axis=0))
      AUC_ROC.append(np.mean(np.array(ROC),axis=0))

      Precision.append(np.mean(np.array(prec),axis=0))
      Recall.append(np.mean(np.array(rec),axis=0))
      f1score.append(np.mean(np.array(fscore),axis=0))

      pred1=np.concatenate(pred,axis=0)
      act1=np.concatenate(act,axis=0)
      cnf_matrix.append(confusion_matrix(act1, pred1))

  print("PR", np.mean(AUC_PR,axis=0))
  print("ROC", np.mean(AUC_ROC,axis=0))
  print("ACC", np.mean(accuracy,axis=0))
  print("precision", np.mean(Precision,axis=0))
  print("recall", np.mean(Recall,axis=0))
  print("f1_score", np.mean(f1score,axis=0))

  # np.save(os.path.join(SaveResults, accname),  accuracy)
  # np.save(os.path.join(SaveResults, savenamef1+str(th)),  f1score)
  # np.save(os.path.join(SaveResults, cfname+str(th)),  cnf_matrix)
  #
  # # np.save(os.path.join(SaveResults, fprname),  fpr)
  # # np.save(os.path.join(SaveResults, tprname),  tpr)
  # np.save(os.path.join(SaveResults, prname), AUC_PR)
  # np.save(os.path.join(SaveResults, rocname),  AUC_ROC)
  # np.save(os.path.join(SaveResults, precname),Precision)
  # np.save(os.path.join(SaveResults, recname), Recall)
  #
  # #
  # #
  # # ####################################
  #
  #
  #
  # fold_no=0
  # FoldNum=6
  # cnt=0
  # kfold = KFold(n_splits=FoldNum, shuffle=False)
  # for trainindx, testindx in kfold.split(range(24)):
  #   if indx=='test':
  #     ind=testindx
  #   else:
  #     ind=trainindx
  #   fold_no=fold_no+1
  #   for j in [0,8,11]:
  #
  #     _,_,_,_,_,x, y, mi,mi_diff,spect=ReadMatFiles(dirname,dirname2,ind,seq_len,diff)
  #     X_train=Xtrain(cnn,spect1,smile,diff,smile_new_arch,twodcnn,cnnsmilespect,x[j],y[j],mi[j],mi_diff[j],spect[j])
  #     ModelName1=modelname+'_fold'+str(fold_no)+'_epoch_'+str(Noepoch)+'_batchsize_'+str(batch_size)+'.h5'
  #     model1=tf.keras.models.load_model(os.path.join(modeldir,ModelName1),custom_objects={"f1_score":f1_score,"auc_roc":auc_roc,"precision":precision,"recall2":recall2,"auc_pr":auc_pr})
  #     ypred_plot=model1.predict(X_train)
  #     if gru==1:
  #       y1 = y[j][:, 2]
  #       ypred_plot= ypred_plot[:, 2]
  #     else:
  #       y1 = y[j]
  #
  #     cnt=cnt+1
  #     plt.subplot(6,3,cnt)
  #     plt.plot(range(len(y1)),y1 )
  #     plt.plot(range(len(y1)),ypred_plot)
  #
  # plt.suptitle(modelname+'_EDFNo_'+str(j+1)+'_'+indx+'_fold_'+str(fold_no))
  #
  # plt.savefig(SaveResultsTruePred+'/'+modelname+'_epoch_'+str(Noepoch)+'_'+indx+'.pdf', format='pdf', bbox_inches = 'tight')
  # # plt.clf()


  print("--- %s seconds ---" % (time.time() - start_time))

dirname='/media/datadrive/bsalafian/6FoldCrossSMILE'
dirname2='/media/datadrive/bsalafian/AllMatFiles'
modeldir='/home/baharsalafian/LastExperiment_model_6fold'

SaveResults='/home/baharsalafian/Results_6fold_JBHI_allexperiments'

SaveResultsTruePred='/home/baharsalafian/TruePredPlots_6fold_JBHI_allexperiments'

ModelTrain(dirname,dirname2,modeldir,SaveResults,SaveResultsTruePred,'CNN_SMILE_MoreDense_AddDrop_6Fold',seq_len=1,cnn=0,spect1=0,smile=1,diff=0,twodcnn=0,cnnsmilespect=0,smile_new_arch=0,indx='test',gru=0,Noepoch=100,batch_size=256)
# CNNSMILE10times_Decay.5_lr.001_NoAct
## '2DCNN10times' : name of the model that you wanna load
