# -*- coding: utf-8 -*-
"""Copy of CNNSMILEGRU_Bs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fgyv5Og_PPfexz3ih-4uEJqa-PfQsKSA
"""
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="5"
import statistics
from keras.models import Model
from keras.utils.generic_utils import get_custom_objects
from keras import optimizers, regularizers
import keras.backend as K
from keras import regularizers
from tensorflow.keras.layers import InputLayer
from keras.layers import Input
import time
import tensorflow as tf
import os
import scipy
import h5py
import glob, os
# import BaseLineModel
from scipy.io import loadmat
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
# from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten,Concatenate
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
from sklearn.metrics import f1_score,plot_roc_curve
from sklearn.metrics import plot_precision_recall_curve,roc_curve,roc_auc_score,auc
from sklearn.metrics import precision_recall_fscore_support,precision_recall_curve
import matplotlib.pyplot as plt;
# from keras.optimizers import Adam
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import BatchNormalization
from keras.utils import np_utils
from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D, GlobalAveragePooling1D
from keras.layers.advanced_activations import LeakyReLU
from keras.preprocessing.image import ImageDataGenerator
from sklearn import preprocessing
from keras import regularizers
from numpy import mean
from numpy import std
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.layers import InputLayer
from keras.layers import Input
# from google.colab import drive
from sklearn.model_selection import LeaveOneOut
import gc
gc.collect()

def PatientsName():

  Name=['chb01','chb02','chb03','chb04','chb05','chb06','chb07','chb08','chb09','chb10',
  'chb11','chb12','chb13','chb14','chb15','chb16','chb17','chb18','chb19','chb20','chb21',
  'chb22','chb23','chb24']
  return Name

def PatientsEDFFile(dirname):

  os.chdir(dirname)
  a=[]
  X=[]
  Y=[]
  k=0
  for file in glob.glob("*.mat"):
      a.append(file)
      # print(a)
  return a

def recall2(y_true, y_pred):

  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
  recall_m = true_positives / (possible_positives + K.epsilon())
  return recall_m

def precision(y_true, y_pred):

  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
  precision_m = true_positives / (predicted_positives + K.epsilon())
  return precision_m

def AUCPR(y_true, y_pred):

  precision, recall, _ = precision_recall_curve(y_true, y_pred)

  PR1=auc(recall, precision)

  return PR1
# def f1_score(y_true, y_pred):
  # precision_m = precision(y_true, y_pred)
  # recall_m = recall(y_true, y_pred)
  # return 2*((precision_m*recall_m)/(precision_m+recall_m+K.epsilon()))
def f1_score(y_true, y_pred,threshold_shift=0):

  y_pred = K.clip(y_pred, 0, 1)
  # shifting the prediction threshold from .5 if needed
  y_pred_bin = K.round(y_pred + threshold_shift)
  tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()
  fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))
  fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))
  precision1 = tp / (tp + fp)
  recall1 = tp / (tp + fn)
  p = precision1
  r = recall1
  return 2 * ((p * r) / (p + r))

def auc_roc(y_true, y_pred):

  return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)

def auc_pr(y_true, y_pred):

  return tf.py_function(AUCPR, (y_true, y_pred), tf.double)


def create_sub_seq(nn_input, len_ss, labels=None):

  """
  This function creates all sub sequences for the batch
  """
  n_seq = nn_input.shape[0]
  len_seq = nn_input.shape[1]
  n_ss = len_seq - len_ss + 1
  new_labels = []
  if nn_input.ndim == 3:
    new_inp = np.zeros((n_ss*n_seq,len_ss,nn_input.shape[2]))
  elif nn_input.ndim == 4:
    new_inp = np.zeros((n_ss*n_seq,len_ss,nn_input.shape[2], nn_input.shape[3]))
  if labels is not None:
      dim_labels = labels.shape
      if len(dim_labels) == 2:
          new_labels = np.zeros((n_ss*n_seq, len_ss))
      elif len(dim_labels) == 3:
          new_labels = np.zeros((n_ss * n_seq, len_ss, dim_labels[2]))
  k = 0
  for i in range(n_seq):
      for j in range(n_ss):
          new_inp[k] = nn_input[i, j:j + len_ss, :]
          if labels is not None:
              if len(dim_labels) == 2:
                  new_labels[k, :] = labels[i, j:j + len_ss]
              elif len(dim_labels) == 3:
                  new_labels[k, :, :] = labels[i, j:j + len_ss, :]
          k += 1
  return new_inp, n_ss, new_labels


def SelectIndx(EDFNo,ind):

  EDF=[]
  EDFFiles=[]
  Name=[]
  EDF=PatientsEDFFile(dirname)
  Name=PatientsName()

  indx=[]
  for j in range(len(ind)):
    # print(j)
    indices = [i for i, elem in enumerate(EDF) if Name[j] in elem]
    indx.append(indices)

  indtest=[]
  indtrain=[]
  for i in range(len(indx)):

    for k in range(len(indx[i])):
      # print(len(indx[i]))

      if k==EDFNo:
        indtest.append(indx[i][k])
        # print(indtest)

      else:
        indtrain.append(indx[i][k])
        # print(indtrain)

  # indtest=np.concatenate(indtest,axis=0)
  # indtrain=np.concatenate(indtrain,axis=0)
  # print(len(indtest))
  return indtest,indtrain




def ReadMatFiles(dirname,dirname2,ind, seq_len=1,diff=None):

  EDF=[]
  EDFFiles=[]
  Name=[]
  EDF=PatientsEDFFile(dirname)
  Name=PatientsName()
  Xfile=[]
  Yfile=[]
  spec=[]

  MI_all=[]
  X=[]
  Y=[]
  MI_diff_all=[]
  # print(ind)
  for k in range(len(ind)):

    print(EDF[ind[k]])
    matfile=loadmat(os.path.join(dirname,EDF[ind[k]]))

    Name2=EDF[ind[k]].split('.')
    # matfile2=loadmat(os.path.join(dirname2,Name2[0]+'_Spectogram.mat'))
    matfile2=loadmat(os.path.join(dirname2,EDF[ind[k]]))
    Spectrogram=matfile2['spectogram']
    x=matfile['X_4sec']
    y=matfile['Y_label_4sec']
    mi=matfile['estimated_MI']

    # print("this is new", mi.shape)
    # time.sleep(5)
    y=np.transpose(y)

    start_idx = np.argmax(y>0)
    a = y == 1
    end_idx = len(a) - np.argmax(np.flip(a)) - 1
    real_y = np.zeros_like(y)
    real_y[start_idx:end_idx+1] = 1
    MI=np.zeros((mi.shape[0],153))
    # MI=mi
    for j in range(mi.shape[0]):
      mi2=mi[j,:,:]
      mi_mod=list(mi2[np.triu_indices(18,k=1)])
      MI[j,:]=mi_mod


    MI_diff=[]
    if seq_len > 1:
      real_y = np.expand_dims(real_y, axis=0)
      x = np.expand_dims(x, axis=0)
      MI = np.expand_dims(MI, axis=0)
      # print(MI.shape)
      x, _ , real_y = create_sub_seq(x, seq_len, labels=real_y)
      MI, _, _ = create_sub_seq(MI, seq_len)
      # print(x.shape)
      # print(real_y.shape)
      # print(MI.shape)

    if diff is not None:

      for j in range(MI.shape[0]-1):

        MI_diff.append(MI[j+1]-MI[j])

      MI_diff=np.array(MI_diff)
      MI=MI[1:]
      x=x[1:]
      real_y=real_y[1:]
      Spectrogram=Spectrogram[1:]
    X.append(x)
    Y.append(real_y)
    MI_all.append(MI)
    MI_diff_all.append(MI_diff)
    spec.append(Spectrogram)


  X=np.concatenate(X,axis=0)
  Y=np.concatenate(Y,axis=0)
  spec=np.concatenate(spec,axis=0)

  MI_all=np.concatenate(MI_all,axis=0)
  MI_diff_all=np.concatenate(MI_diff_all,axis=0)
  # print(Y)
  # print(X.shape)
  # print(Y.shape)
  # print(MI_all.shape)
  # print(MI_diff_all.shape)

  return X, Y, MI_all, MI_diff_all,spec

def Xtrain(cnn,smile,diff,twodcnn,spectrogram,cnnsmilespect,gru,x,y,mi,mi_diff,spec):

  if cnn==1:
    X_train=x

  if gru==1:
    X_train=x

  if smile==1:
    # X_train=np.concatenate((x,mi),axis=1)
    X_train=[x,mi]

  if diff==1:
    X_train=[x,mi,mi_diff]

  if twodcnn==1:
    x2d=x.reshape(x.shape[0],x.shape[2],x.shape[1],1)
    X_train=x2d

  if spectrogram==1:

    X_train=spec

  if cnnsmilespect==1:

    X_train=[x,spec,mi]

  return X_train


def ModifiedList(ListName):
  MyList=ListName
  MyList=np.around(MyList,3)
  # MyList=MyList*100
  return MyList

def MeanStdVar(ListName):

  mylist=ModifiedList(ListName)

  ListMean=np.mean(mylist,axis=0)
  ListStd=np.std(mylist,axis=0)
  ListVar=np.var(mylist,axis=0)

  return ListMean*100,ListStd,ListVar



def ModelTrain(dirname,dirname2,modeldir,SaveResults,SaveResultsTruePred,modelname,seq_len,cnn,smile,diff,twodcnn,spectrogram,cnnsmilespect,indx,gru,epoch,l2_size,drop_size,batchSize,noise):

  FoldNum=6
  kfold = KFold(n_splits=FoldNum, shuffle=False)
  start_time = time.time()
  fold_no=0

  savenamef1='fscore_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)
  cfname='cfmat_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)
  fprname='fpr_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)
  tprname='tpr_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)
  prname='PR_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)
  rocname='ROC_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)

  precname='Precision_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)

  recname='Recall_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)

  accname='Accuracy_'+modelname+'_'+indx+'_'+'epoch_'+str(epoch)+'_batchsize_'+str(batchSize)


  ind1=range(0,24)
  for th in [0.7]:

    fold_no=0

    fpr=[]
    tpr=[]
    PR=[]
    ROC=[]
    pred=[]
    act=[]
    fscore=[]
    prec=[]
    rec=[]
    Acc=[]
    for i in range(2):

      testindx,trainindx=SelectIndx(i,ind1)

      if indx=='test':
        ind=testindx
      else:
        ind=trainindx
      fold_no=fold_no+1

      # ModelName1=modelname+'_fold'+str(fold_no)+'_epoch_'+str(epoch)+'_batchsize_'+str(batchSize)+'.h5'
      # modelname+'_fold'+str(fold_no)+'_LR_1e-5'+str(initLR)+'_epoch_'+str(epoch+init_epoch)+'_l2Size_'+str(l2_size)+'_DropSize_'+str(drop_size)+'_batchsize_'+str(batchSize)+'.h5')
      ModelName1=modelname+'_fold'+str(fold_no)+'_epoch_'+str(epoch)+'_batchsize_'+str(batchSize)+'_l2size_'+str(l2_size)+'_dropsize_'+str(drop_size)+'Noise'+str(noise)+'.h5'

      model1=tf.keras.models.load_model(os.path.join(modeldir,ModelName1),custom_objects={"f1_score":f1_score,"auc_roc":auc_roc,"precision":precision,"recall2":recall2,"auc_pr":auc_pr})


      x, y, mi,mi_diff,spec=ReadMatFiles(dirname,dirname2,ind,seq_len,diff)
      # print(x[0].shape)
      # print(y[0].shape)
      # print(mi[0].shape)
      # print(spec[0].shape)
      # for k in range(len(x)):

      X=x
      Y=y
      MI_all=mi

      MI_diff_all=mi_diff
      spec1=spec

      print(X.shape)



      X_train=Xtrain(cnn,smile,diff,twodcnn,spectrogram,cnnsmilespect,gru,X,Y,MI_all,MI_diff_all,spec1)



      ypred=model1.predict(X_train)
        # print(ypred.shape)

        # print("this is prediction" ,ypred)
        # time.sleep(3)
      ypred_th = (ypred > th).astype(int)

      if gru==1:

        Y = Y[:, 2]
        ypred= ypred[:, 2]
        ypred_th= (ypred > th).astype(int)

  #
  #
      fpr1, tpr1, _ = roc_curve(Y, ypred)
      # Precision1, Recall1, threshold1 = precision_recall_curve(Y, ypred)
      # print(threshold1)
      # time.sleep(10)
        #
        # PR1=auc(Precision, Recall)
      PR1=AUCPR(Y, ypred)
      ROC1=roc_auc_score(Y,ypred)
      fpr.append(fpr1)
      tpr.append(tpr1)

  #     PR.append(PR1)
  #     ROC.append(ROC1)

  #     Acc.append(accuracy_score(Y,ypred_th))
  # #
      Precision1, Recall1, f1, _ = precision_recall_fscore_support(Y, ypred_th,average='binary')
  # #
  #     pred.append(list(ypred_th))
  #     act.append(list(Y))
  #     fscore.append(f1)
  #     prec.append(Precision1)
  #     rec.append(Recall1)

  #     # accuracy.append(np.mean(np.array(Acc),axis=0))

  #     # AUC_PR.append(np.mean(np.array(PR),axis=0))
  #     # AUC_ROC.append(np.mean(np.array(ROC),axis=0))
  #     #
  #     # Precision.append(np.mean(np.array(prec),axis=0))
  #     # Recall.append(np.mean(np.array(rec),axis=0))
  #     # f1score.append(np.mean(np.array(fscore),axis=0))

  #     # pred1=np.concatenate(pred,axis=0)
  #     # act1=np.concatenate(act,axis=0)
  #     # cnf_matrix.append(confusion_matrix(act1, pred1))
  #   PRmean,PRstd,_=MeanStdVar(PR)
  #   ROCmean,ROCstd,_=MeanStdVar(ROC)
  #   Accmean,Accstd,_=MeanStdVar(Acc)
  #   precmean,precstd,_=MeanStdVar(prec)
  #   recmean,recstd,_=MeanStdVar(rec)
  #   fscoremean,fscorestd,_=MeanStdVar(fscore)

  #   print("PR ", PRmean,PRstd)
  #   print("ROC ", ROCmean,ROCstd)
  #   print("ACC ", Accmean,Accstd)
  #   print("precision ", precmean,precstd)
  #   print("recall ", recmean,recstd)
  #   print("f1_score ", fscoremean,fscorestd)
  #   # print(threshold1)
  #   time.sleep(10)

  #   np.save(os.path.join(SaveResults, accname),  Acc)

  #   np.save(os.path.join(SaveResults, savenamef1+'_'+str(th)),  fscore)
  #   # np.save(os.path.join(SaveResults, cfname+'_'+str(th)),  cnf_matrix)
  # #
  #   np.save(os.path.join(SaveResults, prname), PR)
  #   np.save(os.path.join(SaveResults, rocname),  ROC)
    np.save(os.path.join(SaveResults, fprname),fpr)
    np.save(os.path.join(SaveResults, tprname), tpr)
    # np.save(os.path.join(SaveResults, precname),prec)
  #   np.save(os.path.join(SaveResults, recname), rec)
  # ###################################
#   ind1=range(0,24)
#   ####################################
#   cnt=0
#   fold_no=0
#
#   for q in range(2):
#
#     testindx,trainindx=SelectIndx(q,ind1)
#     if indx=='test':
#       ind=testindx
#     else:
#       ind=trainindx
#     fold_no=fold_no+1
#     x, y, mi,mi_diff,spec=ReadMatFiles(dirname,dirname2,ind,seq_len,diff)
#
#     for j in [0,4,9]:
#
#
#       X_train=Xtrain(cnn,smile,diff,twodcnn,spectrogram,cnnsmilespect,gru,x[j],y[j],mi[j],mi_diff[j],spec[j])
#
#       # ModelName1=modelname+'_fold'+str(fold_no)+'_epoch_'+str(epoch)+'_batchsize_'+str(batchSize)+'.h5'
#       ModelName1=modelname+'_fold'+str(fold_no)+'_epoch_'+str(epoch)+'_batchsize_'+str(batchSize)+'_l2size_'+str(l2_size)+'_dropsize_'+str(drop_size)+'Noise'+str(noise)+'.h5'
# # CNN_24Testfiles_MoreDense_init_0.0001_fold1_epoch_100_batchsize_256_l2size_None_dropsize_0Noise0
#       model1=tf.keras.models.load_model(os.path.join(modeldir,ModelName1),custom_objects={"f1_score":f1_score,"auc_roc":auc_roc,"precision":precision,"recall2":recall2,"auc_pr":auc_pr})
#
#       ypred_plot=model1.predict(X_train)
#       if gru==1:
#         y = y[j][:, 2]
#         ypred_plot= ypred_plot[:, 2]
#       else:
#         y1 = y[j]
#       print(y1.shape)
#       cnt=cnt+1
#       plt.subplot(2,3,cnt)
#
#       plt.plot(range(len(y1)), y1)
#       plt.plot(range(len(y1)),ypred_plot)
#
#   plt.suptitle(modelname+'_epoch_'+str(epoch)+'_'+indx+'_batchsize_'+str(batchSize)+'_fold_'+str(fold_no))
#
#   plt.savefig(SaveResultsTruePred+'/'+modelname+'_epoch_'+str(epoch)+'_'+indx+'_batchsize_'+str(batchSize)+'.pdf', format='pdf', bbox_inches = 'tight')
#     # plt.clf()
#

  print("--- %s seconds ---" % (time.time() - start_time))

# for i in [0.1,0.25,0.5]:
#
#   for j in [128,256,512]:
#
#     for k in [None,0.0001,0.001,0.01]:

dirname='/media/datadrive/bsalafian/6FoldCrossSMILE'
dirname2='/media/datadrive/bsalafian/AllMatFiles'
modeldir='/home/baharsalafian/LastExperiment_model_Allcase'

SaveResults='/home/baharsalafian/Results_Allcase_JBHI_Lastexperiments'
SaveResultsTruePred='/home/baharsalafian/TruePredPlots_Allcase_JBHI_Lastexperiments'
i=0
k=None
j=256
# n=0
ModelTrain(dirname,dirname2,modeldir,SaveResults,SaveResultsTruePred,'CNNSMILEGRU_24Testfiles_init_0.0001',seq_len=3,cnn=0,smile=1,diff=0,twodcnn=0,spectrogram=0,cnnsmilespect=0,indx='test',gru=1,epoch=100,l2_size=k,drop_size=i,batchSize=j,noise=0)


## '2DCNN10times' : name of the model that you wanna load
# CNNSMILESpectrogram10times_Decay.5_LR.001_24Testfiles_KerasMet_fold1_LR_1e-05_epoch_1500_l2Size_None_DropSize_0_batchsize_256.h5
#
# CNNSMILESpectrogram10times_Decay.5_LR.001_24Testfiles_KerasMet_fold1_LR_1e-5_epoch_1500_l2Size_None_DropSize_0_batchsize_256
